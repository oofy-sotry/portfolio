#!/usr/bin/env python3
"""
HuggingFace ëª¨ë¸ ì‚¬ì „ ë‹¤ìš´ë¡œë“œ ìŠ¤í¬ë¦½íŠ¸
"""

import os
import sys
from transformers import AutoTokenizer, AutoModelForCausalLM, AutoModelForSeq2SeqLM
from sentence_transformers import SentenceTransformer

def download_models():
    """ê¸°ë³¸ ëª¨ë¸ë“¤ì„ ì‚¬ì „ ë‹¤ìš´ë¡œë“œ"""
    print("ğŸš€ HuggingFace ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì‹œì‘...")
    
    models = {
        'embedding': 'sentence-transformers/all-MiniLM-L6-v2',
        'generation': 'distilgpt2', 
        'summarization': 'facebook/bart-large-cnn'
    }
    
    for model_type, model_name in models.items():
        try:
            print(f"ğŸ“¥ {model_type} ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì¤‘: {model_name}")
            
            if model_type == 'embedding':
                model = SentenceTransformer(model_name)
                print(f"âœ… {model_type} ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ")
                
            elif model_type == 'generation':
                tokenizer = AutoTokenizer.from_pretrained(model_name)
                model = AutoModelForCausalLM.from_pretrained(model_name)
                print(f"âœ… {model_type} ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ")
                
            elif model_type == 'summarization':
                tokenizer = AutoTokenizer.from_pretrained(model_name)
                model = AutoModelForSeq2SeqLM.from_pretrained(model_name)
                print(f"âœ… {model_type} ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ")
                
        except Exception as e:
            print(f"âŒ {model_type} ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {e}")
    
    print("ğŸ‰ ëª¨ë“  ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ!")

if __name__ == "__main__":
    download_models()