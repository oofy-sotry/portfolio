#!/usr/bin/env python3
"""
HuggingFace ëª¨ë¸ ì‚¬ì „ ë‹¤ìš´ë¡œë“œ ìŠ¤í¬ë¦½íŠ¸
"""

import os
import sys
from transformers import AutoTokenizer, AutoModelForCausalLM, AutoModelForSeq2SeqLM
from sentence_transformers import SentenceTransformer

def download_models():
    """ê¸°ë³¸ ëª¨ë¸ë“¤ì„ ì‚¬ì „ ë‹¤ìš´ë¡œë“œí•˜ê³  ./models ë””ë ‰í† ë¦¬ì— ì €ì¥"""
    # ìŠ¤í¬ë¦½íŠ¸ê°€ ìˆëŠ” ë””ë ‰í† ë¦¬ ì°¾ê¸°
    script_dir = os.path.dirname(os.path.abspath(__file__))
    project_root = os.path.dirname(script_dir)
    models_dir = os.path.join(project_root, "models")
    
    # models ë””ë ‰í† ë¦¬ ìƒì„±
    os.makedirs(models_dir, exist_ok=True)
    print(f"ğŸ“ ëª¨ë¸ ì €ì¥ ê²½ë¡œ: {models_dir}")
    
    print("ğŸš€ HuggingFace ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì‹œì‘...")
    
    models = {
        'embedding': 'sentence-transformers/all-MiniLM-L6-v2',
        'generation': 'distilgpt2', 
        'summarization': 'facebook/bart-large-cnn'
    }
    
    download_results = {}
    
    for model_type, model_name in models.items():
        try:
            print(f"\nğŸ“¥ {model_type} ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì¤‘: {model_name}")
            
            model_save_path = os.path.join(models_dir, f"{model_type}_model")
            
            if model_type == 'embedding':
                # ì„ë² ë”© ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ë° ì €ì¥
                model = SentenceTransformer(model_name)
                model.save(model_save_path)
                print(f"âœ… {model_type} ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ë° ì €ì¥ ì™„ë£Œ")
                print(f"   ì €ì¥ ìœ„ì¹˜: {model_save_path}")
                
            elif model_type == 'generation':
                # ìƒì„± ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ë° ì €ì¥
                tokenizer = AutoTokenizer.from_pretrained(model_name)
                model = AutoModelForCausalLM.from_pretrained(model_name)
                tokenizer.save_pretrained(model_save_path)
                model.save_pretrained(model_save_path)
                print(f"âœ… {model_type} ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ë° ì €ì¥ ì™„ë£Œ")
                print(f"   ì €ì¥ ìœ„ì¹˜: {model_save_path}")
                
            elif model_type == 'summarization':
                # ìš”ì•½ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ë° ì €ì¥
                tokenizer = AutoTokenizer.from_pretrained(model_name)
                model = AutoModelForSeq2SeqLM.from_pretrained(model_name)
                tokenizer.save_pretrained(model_save_path)
                model.save_pretrained(model_save_path)
                print(f"âœ… {model_type} ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ë° ì €ì¥ ì™„ë£Œ")
                print(f"   ì €ì¥ ìœ„ì¹˜: {model_save_path}")
            
            # ì €ì¥ í™•ì¸
            if os.path.exists(model_save_path) and os.path.isdir(model_save_path):
                # ë””ë ‰í† ë¦¬ ë‚´ íŒŒì¼ ê°œìˆ˜ í™•ì¸
                file_count = len([f for f in os.listdir(model_save_path) if os.path.isfile(os.path.join(model_save_path, f))])
                if file_count > 0:
                    download_results[model_type] = True
                    print(f"   âœ“ ì €ì¥ í™•ì¸: {file_count}ê°œ íŒŒì¼")
                else:
                    download_results[model_type] = False
                    print(f"   âš ï¸ ì €ì¥ ê²½ë¡œëŠ” ì¡´ì¬í•˜ì§€ë§Œ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤")
            else:
                download_results[model_type] = False
                print(f"   âŒ ì €ì¥ ê²½ë¡œê°€ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
                
        except Exception as e:
            print(f"âŒ {model_type} ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {e}")
            import traceback
            traceback.print_exc()
            download_results[model_type] = False
    
    # ìµœì¢… ê²°ê³¼ í™•ì¸
    print("\n" + "="*60)
    print("ğŸ“Š ë‹¤ìš´ë¡œë“œ ê²°ê³¼ ìš”ì•½:")
    print("="*60)
    
    all_success = True
    for model_type, success in download_results.items():
        status = "âœ… ì„±ê³µ" if success else "âŒ ì‹¤íŒ¨"
        print(f"  {model_type:15s}: {status}")
        if not success:
            all_success = False
    
    print("="*60)
    
    if all_success:
        print("ğŸ‰ ëª¨ë“  ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ë° ì €ì¥ ì™„ë£Œ!")
        return 0
    else:
        print("âš ï¸ ì¼ë¶€ ëª¨ë¸ ë‹¤ìš´ë¡œë“œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
        print("ğŸ’¡ Docker ì»¨í…Œì´ë„ˆ ì‹¤í–‰ ì‹œ HuggingFaceì—ì„œ ìë™ìœ¼ë¡œ ë‹¤ìš´ë¡œë“œë©ë‹ˆë‹¤.")
        return 1

if __name__ == "__main__":
    exit_code = download_models()
    sys.exit(exit_code)