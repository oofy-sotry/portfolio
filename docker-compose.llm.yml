version: '3.8'

services:
  # 기존 서비스들
  web:
    build: .
    ports:
      - "5000:5000"
    environment:
      - FLASK_APP=app
      - FLASK_ENV=production
      - DATABASE_URL=mysql+pymysql://root:password@db:3306/portfolio_db
      - SECRET_KEY=your-secret-key-change-in-production
      - ELASTICSEARCH_URL=http://elasticsearch:9200
      - LLM_SERVICE_URL=http://llm-service:8000
    depends_on:
      - db
      - elasticsearch
      - llm-service
    volumes:
      - ./app:/app/app
    restart: unless-stopped

  db:
    image: mariadb:10.11
    environment:
      - MYSQL_ROOT_PASSWORD=password
      - MYSQL_DATABASE=portfolio_db
      - MYSQL_USER=portfolio_user
      - MYSQL_PASSWORD=portfolio_password
    volumes:
      - db_data:/var/lib/mysql
    ports:
      - "3306:3306"
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "mysqladmin", "ping", "-h", "localhost"]
      timeout: 20s
      retries: 10

  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.11.0
    environment:
      - discovery.type=single-node
      - xpack.security.enabled=false
      - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
    ports:
      - "9200:9200"
    volumes:
      - es_data:/usr/share/elasticsearch/data
    restart: unless-stopped

  # 별도 LLM 서비스 (선택사항)
  llm-service:
    image: huggingface/transformers-pytorch-gpu:latest
    environment:
      - TRANSFORMERS_CACHE=/cache
    volumes:
      - llm_cache:/cache
      - ./llm_service:/app
    ports:
      - "8000:8000"
    command: python /app/llm_server.py
    restart: unless-stopped
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]

  nginx:
    image: nginx:alpine
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf
      - ./ssl:/etc/nginx/ssl
    depends_on:
      - web
    restart: unless-stopped

volumes:
  db_data:
  es_data:
  llm_cache:
